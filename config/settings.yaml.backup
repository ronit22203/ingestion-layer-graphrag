# Configuration for Medical Data Ingestion Pipeline
# All paths are relative to the project root

# Project Structure
project_root: "."
input_dir: "data/raw"
log_file: "logs/ingestion.log"

# Pipeline Stage 1: OCR (PDF -> OCR JSON)
ocr:
  # Surya OCR configuration
  langs: ["en"]
  device: "mps"                    # mps=Apple Silicon GPU, cpu=fallback
  det_batch_size: 2                # Detection batch size
  rec_batch_size: 16               # Recognition batch size
  image_scale: 2                   # 2=144 DPI (good), 3=216 DPI (better for small text)

# Pipeline Stage 2: Convert (OCR JSON -> Markdown)
conversion:
  # SuryaToMarkdown settings
  infer_headers: true              # Detect headers from bold text & layout
  preserve_spacing: true           # Preserve paragraph gaps

# Pipeline Stage 3: Clean (Markdown -> Cleaned)
cleaning:
  remove_phantom_links: true       # Remove []() artifacts
  remove_images: true              # Remove ![...](...) 
  linearize_tables: true           # Convert tables to readable format
  fix_hyphenation: true            # Merge hyphenated words
  collapse_whitespace: true        # Remove excessive newlines

# Pipeline Stage 4: Chunk (Cleaned -> Chunks JSON)
chunking:
  max_tokens: 500                 # Tokens per chunk
  chunk_overlap: 300               # Overlap between chunks
  headers_to_split: ["#", "##", "###"]
  respect_atomic_blocks: true      # Never split lists/code blocks

# Pipeline Stage 5: Vectorize (Chunks -> Qdrant)
vectorization:
  # Embedding model
  model_name: "BAAI/bge-small-en-v1.5"
  embedding_dim: 384
  
  # Qdrant settings
  qdrant_url: "http://localhost:6333"
  collection_name: "medical_papers"
  
  # Vectorization batch size
  batch_size: 64

# Logging & Debug
logging:
  level: "INFO"                    # DEBUG, INFO, WARNING, ERROR
  save_artifacts: true             # Save intermediate outputs

